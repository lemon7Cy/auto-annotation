# -*- coding: utf-8 -*-
"""
æ¨¡å¼4: æç¤ºè¯å¼æ ‡æ³¨ç•Œé¢
ä»…èƒŒæ™¯å›¾ï¼Œæ— ä¸‹æ–¹æç¤ºåŒºåŸŸ
ä»æ–‡ä»¶åè§£æç±»åˆ«é€‰é¡¹ï¼ˆæ ¼å¼ï¼šç±»åˆ«1_ç±»åˆ«2_ç±»åˆ«3_xxx.jpgï¼‰
"""
import os
import cv2
import numpy as np
import json
from typing import List, Dict, Optional
from PyQt5.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QSplitter, QGroupBox,
    QListWidget, QPushButton, QLabel, QFileDialog,
    QMessageBox, QScrollArea, QFrame, QInputDialog,
    QCheckBox
)
from PyQt5.QtGui import QPixmap, QImage
from PyQt5.QtCore import Qt, pyqtSignal

try:
    import ddddocr
except ImportError:
    ddddocr = None

try:
    import onnxruntime
    ONNX_AVAILABLE = True
except ImportError:
    ONNX_AVAILABLE = False


def cv_imread(filepath: str):
    """è¯»å–å›¾ç‰‡ï¼Œæ”¯æŒä¸­æ–‡è·¯å¾„"""
    return cv2.imdecode(np.fromfile(filepath, dtype=np.uint8), cv2.IMREAD_COLOR)


def cv_imwrite(filepath: str, img: np.ndarray):
    """ä¿å­˜å›¾ç‰‡ï¼Œæ”¯æŒä¸­æ–‡è·¯å¾„"""
    ext = os.path.splitext(filepath)[1]
    cv2.imencode(ext, img)[1].tofile(filepath)


class ClickableImageLabel(QLabel):
    """å¯ç‚¹å‡»çš„å›¾ç‰‡æ ‡ç­¾"""
    clicked = pyqtSignal(int)
    
    def __init__(self, index: int, parent=None):
        super().__init__(parent)
        self.index = index
        self.setFrameStyle(QFrame.Box)
        self.setAlignment(Qt.AlignCenter)
        self.setMinimumSize(80, 80)
        self.setMaximumSize(120, 120)
        self.selected = False
        self._update_style()
    
    def set_selected(self, selected: bool):
        self.selected = selected
        self._update_style()
    
    def _update_style(self):
        if self.selected:
            self.setStyleSheet("border: 3px solid #00aa00; background: #e0ffe0;")
        else:
            self.setStyleSheet("border: 1px solid #999; background: #fff;")
    
    def mousePressEvent(self, event):
        if event.button() == Qt.LeftButton:
            self.clicked.emit(self.index)


class HintModeWidget(QWidget):
    """æç¤ºè¯å¼æ ‡æ³¨ç»„ä»¶ - ä»æ–‡ä»¶åè§£æç±»åˆ«"""
    
    def __init__(self, parent=None):
        super().__init__(parent)
        
        # æ•°æ®
        self.data_folder: str = ""
        self.output_folder: str = ""
        self.image_files: List[str] = []
        self.current_idx: int = -1
        
        # YOLO æ£€æµ‹å™¨
        self.detector = None
        
        # å½“å‰å›¾ç‰‡æ•°æ®
        self.current_image: Optional[np.ndarray] = None
        self.detected_crops: List[np.ndarray] = []
        
        # å½“å‰æ–‡ä»¶åè§£æçš„ç±»åˆ«é€‰é¡¹
        self.current_class_options: List[str] = []
        
        # ç±»åˆ«ç»Ÿè®¡
        self.class_counts: Dict[str, int] = {}
        
        # å·²å®Œæˆçš„å›¾ç‰‡ç´¢å¼•
        self.completed_images: set = set()
        
        # OCR å®ä¾‹
        self.ocr = None
        
        # è‡ªå®šä¹‰ OCR ONNX æ¨¡å‹
        self.ocr_onnx_session = None
        self.ocr_label_map: List[str] = []
        
        self._init_ui()
    
    def _init_ui(self):
        layout = QVBoxLayout(self)
        
        # é¡¶éƒ¨å·¥å…·æ 
        toolbar = QHBoxLayout()
        
        self.load_model_btn = QPushButton("åŠ è½½YOLOæ¨¡å‹")
        self.load_model_btn.clicked.connect(self._load_model)
        toolbar.addWidget(self.load_model_btn)
        
        self.load_data_btn = QPushButton("åŠ è½½å›¾ç‰‡æ–‡ä»¶å¤¹")
        self.load_data_btn.clicked.connect(self._load_data_folder)
        toolbar.addWidget(self.load_data_btn)
        
        self.model_label = QLabel("æœªåŠ è½½æ¨¡å‹")
        toolbar.addWidget(self.model_label)
        
        toolbar.addStretch()
        layout.addLayout(toolbar)
        
        # è¯´æ˜æ ‡ç­¾
        hint_label = QLabel("ğŸ“Œ æ–‡ä»¶åæ ¼å¼ï¼šç±»åˆ«1_ç±»åˆ«2_ç±»åˆ«3_xxx.jpg â†’ è‡ªåŠ¨è§£æä¸ºå¯é€‰ç±»åˆ«")
        hint_label.setStyleSheet("color: #666; padding: 5px; background: #f5f5f5; border-radius: 3px;")
        layout.addWidget(hint_label)
        
        # OCR é€‰é¡¹
        ocr_layout = QHBoxLayout()
        self.ocr_check = QCheckBox("å¯ç”¨ OCR è¾…åŠ©")
        if ddddocr is None and not ONNX_AVAILABLE:
            self.ocr_check.setEnabled(False)
            self.ocr_check.setText("å¯ç”¨ OCR è¾…åŠ© (æœªå®‰è£…ä¾èµ–)")
        ocr_layout.addWidget(self.ocr_check)
        
        self.load_ocr_model_btn = QPushButton("åŠ è½½ OCR æ¨¡å‹")
        self.load_ocr_model_btn.clicked.connect(self._load_ocr_model)
        ocr_layout.addWidget(self.load_ocr_model_btn)
        
        self.ocr_model_label = QLabel("æœªåŠ è½½ (ä½¿ç”¨ ddddocr)")
        ocr_layout.addWidget(self.ocr_model_label)
        ocr_layout.addStretch()
        layout.addLayout(ocr_layout)
        
        # ä¸»å†…å®¹åŒº
        splitter = QSplitter(Qt.Horizontal)
        layout.addWidget(splitter)
        
        # å·¦ä¾§ï¼šå›¾åƒæ˜¾ç¤ºåŒº
        left_widget = QWidget()
        left_layout = QVBoxLayout(left_widget)
        
        # å¤§å›¾æ˜¾ç¤º
        self.bg_label = QLabel("åŠ è½½å›¾ç‰‡æ–‡ä»¶å¤¹åæ˜¾ç¤º")
        self.bg_label.setMinimumSize(300, 200)
        self.bg_label.setMaximumHeight(300)
        self.bg_label.setAlignment(Qt.AlignCenter)
        self.bg_label.setStyleSheet("border: 1px solid #ccc; background: #f0f0f0;")
        left_layout.addWidget(self.bg_label, 1)
        
        # æ£€æµ‹åˆ°çš„ç›®æ ‡
        crop_group = QGroupBox("æ£€æµ‹åˆ°çš„ç›®æ ‡ï¼ˆç‚¹å‡»é€‰æ‹©åä»ä¸‹æ‹‰èœå•é€‰æ‹©ç±»åˆ«ï¼‰")
        crop_layout = QHBoxLayout(crop_group)
        self.crop_scroll = QScrollArea()
        self.crop_scroll.setWidgetResizable(True)
        self.crop_container = QWidget()
        self.crop_grid = QHBoxLayout(self.crop_container)
        self.crop_grid.setAlignment(Qt.AlignLeft)
        self.crop_scroll.setWidget(self.crop_container)
        self.crop_scroll.setMinimumHeight(150)
        self.crop_scroll.setMaximumHeight(250)
        crop_layout.addWidget(self.crop_scroll)
        left_layout.addWidget(crop_group, 1)
        
        # å½“å‰ç±»åˆ«é€‰é¡¹æ˜¾ç¤º
        options_group = QGroupBox("å½“å‰å¯é€‰ç±»åˆ«ï¼ˆä»æ–‡ä»¶åè§£æï¼‰")
        options_layout = QVBoxLayout(options_group)
        self.options_label = QLabel("åŠ è½½å›¾ç‰‡åæ˜¾ç¤º")
        self.options_label.setWordWrap(True)
        self.options_label.setStyleSheet("font-size: 14px; padding: 10px;")
        options_layout.addWidget(self.options_label)
        left_layout.addWidget(options_group)
        
        splitter.addWidget(left_widget)
        
        # å³ä¾§ï¼šåˆ—è¡¨å’Œç»Ÿè®¡
        right_widget = QWidget()
        right_layout = QVBoxLayout(right_widget)
        
        # å›¾ç‰‡åˆ—è¡¨
        img_group = QGroupBox("å›¾ç‰‡åˆ—è¡¨")
        img_layout = QVBoxLayout(img_group)
        self.image_list = QListWidget()
        self.image_list.currentRowChanged.connect(self._on_image_selected)
        img_layout.addWidget(self.image_list)
        
        nav_layout = QHBoxLayout()
        self.prev_btn = QPushButton("ä¸Šä¸€å¼ ")
        self.prev_btn.clicked.connect(self._prev_image)
        self.next_btn = QPushButton("ä¸‹ä¸€å¼ ")
        self.next_btn.clicked.connect(self._next_image)
        nav_layout.addWidget(self.prev_btn)
        nav_layout.addWidget(self.next_btn)
        img_layout.addLayout(nav_layout)
        
        # æ ‡æ³¨è¿›åº¦
        self.progress_label = QLabel("è¿›åº¦: 0/0 (0%)")
        self.progress_label.setStyleSheet("font-size: 14px; font-weight: bold; color: #2196F3; padding: 5px;")
        img_layout.addWidget(self.progress_label)
        
        right_layout.addWidget(img_group)
        
        # ç±»åˆ«ç»Ÿè®¡
        stats_group = QGroupBox("ç±»åˆ«ç»Ÿè®¡")
        stats_layout = QVBoxLayout(stats_group)
        self.stats_list = QListWidget()
        stats_layout.addWidget(self.stats_list)
        right_layout.addWidget(stats_group)
        
        # æŒ‰é’®åŒº
        btn_layout = QHBoxLayout()
        
        self.complete_btn = QPushButton("âœ“ å®Œæˆå½“å‰å›¾ç‰‡")
        self.complete_btn.setStyleSheet("background: #4CAF50; color: white; font-weight: bold;")
        self.complete_btn.clicked.connect(self._manual_complete)
        btn_layout.addWidget(self.complete_btn)
        
        self.skip_btn = QPushButton("è·³è¿‡")
        self.skip_btn.clicked.connect(self._next_image)
        btn_layout.addWidget(self.skip_btn)
        
        right_layout.addLayout(btn_layout)
        
        # è¯­åºæ ‡æ³¨é€‰é¡¹
        self.word_order_check = QCheckBox("å¯ç”¨è¯­åºæ ‡æ³¨ (è®°å½•ç‚¹å‡»é¡ºåºä¿å­˜ä¸ºè¯è¯­)")
        right_layout.addWidget(self.word_order_check)
        
        splitter.addWidget(right_widget)
        splitter.setSizes([700, 250])
    
    def _load_model(self):
        """åŠ è½½YOLO ONNXæ¨¡å‹"""
        model_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©YOLO ONNXæ¨¡å‹", "", "ONNXæ¨¡å‹ (*.onnx)"
        )
        if not model_path:
            return
        
        try:
            from yolo_detector import YOLODetector
            self.detector = YOLODetector(model_path)
            self.model_label.setText(f"æ¨¡å‹: {os.path.basename(model_path)}")
        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
    
    def _load_ocr_model(self):
        """åŠ è½½è‡ªå®šä¹‰ OCR ONNX æ¨¡å‹"""
        if not ONNX_AVAILABLE:
            QMessageBox.warning(self, "è­¦å‘Š", "æœªå®‰è£… onnxruntimeï¼Œæ— æ³•åŠ è½½è‡ªå®šä¹‰æ¨¡å‹")
            return
        
        model_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹© OCR ONNX æ¨¡å‹", "", "ONNXæ¨¡å‹ (*.onnx)"
        )
        if not model_path:
            return
        
        # æŸ¥æ‰¾åŒç›®å½•ä¸‹çš„ class.json
        model_dir = os.path.dirname(model_path)
        class_json_path = os.path.join(model_dir, "class.json")
        
        if not os.path.exists(class_json_path):
            QMessageBox.critical(self, "é”™è¯¯", f"æœªæ‰¾åˆ° class.json\nè¯·å°† class.json æ”¾åœ¨æ¨¡å‹åŒç›®å½•ä¸‹:\n{model_dir}")
            return
        
        try:
            # åŠ è½½ç±»åˆ«æ˜ å°„
            with open(class_json_path, 'r', encoding='utf-8') as f:
                self.ocr_label_map = json.load(f)
            
            # åŠ è½½ ONNX æ¨¡å‹
            providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
            self.ocr_onnx_session = onnxruntime.InferenceSession(model_path, providers=providers)
            
            self.ocr_model_label.setText(f"å·²åŠ è½½: {os.path.basename(model_path)} ({len(self.ocr_label_map)} ç±»åˆ«)")
            QMessageBox.information(self, "æˆåŠŸ", f"OCR æ¨¡å‹åŠ è½½æˆåŠŸ\nç±»åˆ«æ•°: {len(self.ocr_label_map)}")
            
        except Exception as e:
            self.ocr_onnx_session = None
            self.ocr_label_map = []
            QMessageBox.critical(self, "é”™è¯¯", f"åŠ è½½ OCR æ¨¡å‹å¤±è´¥: {e}")
    
    def _ocr_predict(self, crop_img: np.ndarray) -> str:
        """ä½¿ç”¨è‡ªå®šä¹‰ ONNX æ¨¡å‹è¿›è¡Œ OCR æ¨ç† (NumPy å®ç°ï¼Œæ— éœ€ torch)"""
        if self.ocr_onnx_session is None or not self.ocr_label_map:
            return ""
        
        try:
            # 1. Resize to 128x128
            img = cv2.resize(crop_img, (128, 128))
            
            # 2. BGR -> RGB
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            # 3. Normalize & Transpose
            # PyTorch Normalize: (image - mean) / std
            # mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
            img = img.astype(np.float32) / 255.0
            mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
            std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
            img = (img - mean) / std
            
            # (H, W, C) -> (C, H, W)
            img = img.transpose(2, 0, 1)
            
            # Add batch dimension: (1, C, H, W)
            img_tensor = np.expand_dims(img, axis=0)
            
            # æ¨ç†
            input_name = self.ocr_onnx_session.get_inputs()[0].name
            outputs = self.ocr_onnx_session.run(None, {input_name: img_tensor})
            output = outputs[0]
            
            # è·å–é¢„æµ‹ç±»åˆ«
            predicted_idx = np.argmax(output, axis=1)[0]
            
            if predicted_idx < len(self.ocr_label_map):
                return self.ocr_label_map[predicted_idx]
            else:
                return ""
        except Exception as e:
            print(f"OCR æ¨ç†å¤±è´¥: {e}")
            return ""

    def _load_data_folder(self):

        """åŠ è½½å›¾ç‰‡æ–‡ä»¶å¤¹"""
        folder = QFileDialog.getExistingDirectory(self, "é€‰æ‹©å›¾ç‰‡æ–‡ä»¶å¤¹")
        if not folder:
            return
        
        self.data_folder = folder
        self.image_files = []
        
        # æ‰«æå›¾ç‰‡æ–‡ä»¶
        for f in sorted(os.listdir(folder)):
            if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                self.image_files.append(os.path.join(folder, f))
        
        # æ›´æ–°åˆ—è¡¨
        self.image_list.clear()
        for i, path in enumerate(self.image_files):
            name = os.path.basename(path)
            if i in self.completed_images:
                name = f"âœ“ {name}"
            self.image_list.addItem(name)
        
        # è¾“å‡ºç›®å½• = æ•°æ®æ–‡ä»¶å¤¹/datasets
        self.output_folder = os.path.join(folder, "datasets")
        
        # åŠ è½½è¿›åº¦
        self._load_progress()
        
        # æ›´æ–°è¿›åº¦æ˜¾ç¤º
        self._update_progress()
        
        # è·³åˆ°ç¬¬ä¸€ä¸ªæœªå®Œæˆçš„
        for i in range(len(self.image_files)):
            if i not in self.completed_images:
                self.image_list.setCurrentRow(i)
                break
        else:
            if self.image_files:
                self.image_list.setCurrentRow(0)
    
    def _save_progress(self):
        """ä¿å­˜æ ‡æ³¨è¿›åº¦"""
        if not self.data_folder:
            return
        
        progress_file = os.path.join(self.data_folder, ".hint_progress.json")
        data = {
            'completed_images': list(self.completed_images),
            'class_counts': self.class_counts
        }
        
        try:
            with open(progress_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ä¿å­˜è¿›åº¦å¤±è´¥: {e}")
    
    def _load_progress(self):
        """åŠ è½½æ ‡æ³¨è¿›åº¦"""
        if not self.data_folder:
            return
        
        progress_file = os.path.join(self.data_folder, ".hint_progress.json")
        if not os.path.exists(progress_file):
            return
        
        try:
            with open(progress_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.completed_images = set(data.get('completed_images', []))
            self.class_counts = data.get('class_counts', {})
            
            # æ›´æ–°åˆ—è¡¨æ˜¾ç¤º
            for i in range(self.image_list.count()):
                if i in self.completed_images:
                    item = self.image_list.item(i)
                    if item and not item.text().startswith('âœ“'):
                        item.setText(f"âœ“ {os.path.basename(self.image_files[i])}")
            
            self._update_stats()
        except Exception as e:
            print(f"åŠ è½½è¿›åº¦å¤±è´¥: {e}")
    
    def _on_image_selected(self, row: int):
        """é€‰æ‹©å›¾ç‰‡"""
        if row < 0 or row >= len(self.image_files):
            return
        
        self.current_idx = row
        self._process_current_image()
    
    def _process_current_image(self):
        """å¤„ç†å½“å‰å›¾ç‰‡"""
        if self.current_idx < 0:
            return
        
        img_path = self.image_files[self.current_idx]
        self.current_image = cv_imread(img_path)
        
        # é‡ç½®å½“å‰è¯­åºåºåˆ—
        self.current_word_sequence = []
        
        if self.current_image is None:
            return
        
        # ä»æ–‡ä»¶åè§£æç±»åˆ«é€‰é¡¹ï¼ˆæ ¼å¼ï¼šç±»å‹1_ç±»å‹2_ç±»å‹3_xxx.jpgï¼‰
        filename = os.path.basename(img_path)
        name_part = os.path.splitext(filename)[0]
        parts = name_part.split('_')
        
        # è¿‡æ»¤ï¼šé•¿åº¦<=8çš„ä¿ç•™ï¼Œæˆ–åŒ…å«ä¸­æ–‡çš„ä¿ç•™
        self.current_class_options = []
        for part in parts:
            part = part.strip()
            if not part:
                continue
            # ä¿ç•™çŸ­å­—ç¬¦ä¸²æˆ–åŒ…å«éASCIIå­—ç¬¦ï¼ˆå¦‚ä¸­æ–‡ï¼‰
            if len(part) <= 8 or not part.isascii():
                self.current_class_options.append(part)
        
        # æ›´æ–°ç±»åˆ«é€‰é¡¹æ˜¾ç¤º
        if self.current_class_options:
            self.options_label.setText("  |  ".join(self.current_class_options))
        else:
            self.options_label.setText("ï¼ˆæœªä»æ–‡ä»¶åè§£æåˆ°ç±»åˆ«é€‰é¡¹ï¼‰")
        
        # æ˜¾ç¤ºå›¾ç‰‡
        self._display_bg(self.current_image)
        
        # è¿è¡Œæ£€æµ‹
        self.detected_crops = []
        
        if self.detector:
            try:
                detections = self.detector.detect(img_path)
                
                for det in detections:
                    bbox = det['bbox']
                    x1, y1, x2, y2 = map(int, bbox)
                    crop = self.current_image[y1:y2, x1:x2].copy()
                    
                    if crop.size > 0:
                        self.detected_crops.append(crop)
                
            except Exception as e:
                print(f"æ£€æµ‹é”™è¯¯: {e}")
        
        # æ˜¾ç¤ºè£å‰ªç»“æœ
        self._display_crops()
    
    def _display_bg(self, img: np.ndarray):
        """æ˜¾ç¤ºèƒŒæ™¯å›¾"""
        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        h, w = rgb.shape[:2]
        qimg = QImage(rgb.data, w, h, w * 3, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(qimg)
        
        scaled = pixmap.scaled(
            self.bg_label.width() - 10,
            self.bg_label.height() - 10,
            Qt.KeepAspectRatio,
            Qt.SmoothTransformation
        )
        self.bg_label.setPixmap(scaled)
    
    def _display_crops(self):
        """æ˜¾ç¤ºæ£€æµ‹åˆ°çš„ç›®æ ‡"""
        while self.crop_grid.count():
            item = self.crop_grid.takeAt(0)
            if item.widget():
                item.widget().deleteLater()
        
        for i, crop in enumerate(self.detected_crops):
            label = ClickableImageLabel(i)
            label.clicked.connect(self._on_crop_clicked)
            
            rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)
            h, w = rgb.shape[:2]
            qimg = QImage(rgb.data, w, h, w * 3, QImage.Format_RGB888)
            pixmap = QPixmap.fromImage(qimg).scaled(
                100, 100, Qt.KeepAspectRatio, Qt.SmoothTransformation
            )
            label.setPixmap(pixmap)
            self.crop_grid.addWidget(label)
    
    def _on_crop_clicked(self, idx: int):
        """ç‚¹å‡»ç›®æ ‡ - å¼¹å‡ºç±»åˆ«é€‰æ‹©"""
        if idx < 0 or idx >= len(self.detected_crops):
            return
        
        crop_img = self.detected_crops[idx]
        
        # å¦‚æœæœ‰ç±»åˆ«é€‰é¡¹ï¼Œä½¿ç”¨ä¸‹æ‹‰é€‰æ‹©
        if self.current_class_options:
            class_name, ok = QInputDialog.getItem(
                self, "é€‰æ‹©ç±»åˆ«",
                "è¯·é€‰æ‹©è¯¥ç›®æ ‡çš„ç±»åˆ«:",
                self.current_class_options,
                0,
                editable=True  # å…è®¸æ‰‹åŠ¨è¾“å…¥
            )
        else:
            # æ²¡æœ‰é€‰é¡¹æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦å¼€å¯ OCR
            default_text = "class_1"
            
            if self.ocr_check.isChecked():
                # ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰ ONNX æ¨¡å‹
                if self.ocr_onnx_session is not None:
                    res = self._ocr_predict(crop_img)
                    if res:
                        default_text = res
                # å¦åˆ™ä½¿ç”¨ ddddocr
                elif ddddocr:
                    if self.ocr is None:
                        self.ocr = ddddocr.DdddOcr(show_ad=False)
                    
                    try:
                        # è½¬æ¢å›¾ç‰‡æ ¼å¼ç”¨äº OCR
                        rgb = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)
                        _, buf = cv2.imencode('.png', rgb)
                        bytes_img = buf.tobytes()
                        res = self.ocr.classification(bytes_img)
                        if res:
                            default_text = res
                    except Exception as e:
                        print(f"OCR è¯†åˆ«å¤±è´¥: {e}")
            
            class_name, ok = QInputDialog.getText(
                self, "è¾“å…¥ç±»åˆ«å",
                "è¯·è¾“å…¥è¯¥ç›®æ ‡çš„ç±»åˆ«å:",
                text=default_text
            )
        
        if not ok or not class_name.strip():
            return
        
        class_name = class_name.strip()
        
        # è®°å½•è¯­åº
        if self.word_order_check.isChecked():
            self.current_word_sequence.append(class_name)
        
        # ä¿å­˜
        self._save_crop(crop_img, class_name)
        
        # ç§»é™¤å·²åˆ†ç±»çš„
        del self.detected_crops[idx]
        self._display_crops()
        
        self._update_stats()
        
        # å¦‚æœéƒ½åˆ†ç±»å®Œäº†ï¼Œä¸‹ä¸€å¼ 
        if not self.detected_crops:
            self._save_word_order()
            self.completed_images.add(self.current_idx)
            item = self.image_list.item(self.current_idx)
            if item:
                item.setText(f"âœ“ {os.path.basename(self.image_files[self.current_idx])}")
            self._save_progress()
            self._update_progress()
            self._next_image()
    
    def _save_crop(self, crop_img: np.ndarray, class_name: str):
        """ä¿å­˜åˆ°åˆ†ç±»æ–‡ä»¶å¤¹"""
        if not self.output_folder:
            self.output_folder = os.path.join(self.data_folder, "datasets")
        
        class_folder = os.path.join(self.output_folder, class_name)
        os.makedirs(class_folder, exist_ok=True)
        
        existing = len([f for f in os.listdir(class_folder) if f.startswith('crop_')])
        crop_path = os.path.join(class_folder, f"crop_{existing + 1:04d}.jpg")
        cv_imwrite(crop_path, crop_img)
        
        self.class_counts[class_name] = self.class_counts.get(class_name, 0) + 1
    
    def _update_stats(self):
        """æ›´æ–°ç»Ÿè®¡"""
        self.stats_list.clear()
        for name, count in sorted(self.class_counts.items()):
            self.stats_list.addItem(f"{name}: {count} å¼ ")
    
    def _update_progress(self):
        """æ›´æ–°æ ‡æ³¨è¿›åº¦"""
        total = len(self.image_files)
        completed = len(self.completed_images)
        if total > 0:
            percent = completed * 100 // total
            self.progress_label.setText(f"è¿›åº¦: {completed}/{total} ({percent}%)")
        else:
            self.progress_label.setText("è¿›åº¦: 0/0 (0%)")

    
    def _save_word_order(self):
        """ä¿å­˜è¯­åºè¯è¯­"""
        if not self.word_order_check.isChecked() or not self.current_word_sequence:
            return
            
        word = "".join(self.current_word_sequence)
        if not word:
            return
            
        idioms_file = os.path.join(self.data_folder, "idioms.txt")
        
        # è¯»å–ç°æœ‰è¯è¯­ä»¥å»é‡
        existing_words = set()
        if os.path.exists(idioms_file):
            try:
                with open(idioms_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        existing_words.add(line.strip())
            except Exception as e:
                print(f"è¯»å–è¯è¯­æ–‡ä»¶å¤±è´¥: {e}")
        
        # å¦‚æœæ˜¯æ–°è¯è¯­ï¼Œè¿½åŠ ä¿å­˜
        if word not in existing_words:
            try:
                with open(idioms_file, 'a', encoding='utf-8') as f:
                    f.write(word + "\n")
                print(f"å·²ä¿å­˜æ–°è¯è¯­: {word}")
            except Exception as e:
                print(f"ä¿å­˜è¯è¯­å¤±è´¥: {e}")

    def _manual_complete(self):
        """æ‰‹åŠ¨å®Œæˆå½“å‰å›¾ç‰‡ï¼Œè·³è¿‡å‰©ä½™ç›®æ ‡"""
        if self.current_idx < 0:
            return
        
        # ä¿å­˜è¯­åºï¼ˆå¦‚æœæœ‰ï¼‰
        self._save_word_order()
        
        # æ ‡è®°ä¸ºå·²å®Œæˆ
        self.completed_images.add(self.current_idx)
        item = self.image_list.item(self.current_idx)
        if item:
            item.setText(f"âœ“ {os.path.basename(self.image_files[self.current_idx])}")
        
        # ä¿å­˜è¿›åº¦
        self._save_progress()
        
        # æ›´æ–°è¿›åº¦æ˜¾ç¤º
        self._update_progress()
        
        # ä¸‹ä¸€å¼ 
        self._next_image()
    
    def _prev_image(self):
        if self.current_idx > 0:
            self.image_list.setCurrentRow(self.current_idx - 1)
    
    def _next_image(self):
        if self.current_idx < len(self.image_files) - 1:
            self.image_list.setCurrentRow(self.current_idx + 1)

